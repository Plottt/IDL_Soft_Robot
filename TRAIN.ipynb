{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact-based Object Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import wandb\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories for classification\n",
    "CATEGORIES = {\n",
    "    'Blueball': 0,\n",
    "    'Box': 1,\n",
    "    'Pencilcase': 2,\n",
    "    'Pinkball': 3,\n",
    "    'StuffedAnimal': 4,\n",
    "    'Tennis': 5,\n",
    "    'Waterbottle': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Dictionary\n",
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 20,\n",
    "    'data_dir': \"/Users/benlee/Documents/college/CMU/Spring 2025/IDL/Project/IDL_code/IDL_Data\",\n",
    "    'checkpoint_dir': \"/Users/benlee/Documents/college/CMU/Spring 2025/IDL/Project/IDL_code/checkpoint\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContactWindowDataset(Dataset):\n",
    "    def __init__(self, data_dir: str, labels: Dict[str, int] = None, window_size: int = 50, step_size: int = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Directory containing the .txt files\n",
    "            labels (Dict[str, int]): Dictionary mapping categories to class labels\n",
    "            window_size (int): Size of the sliding window (smaller = more samples)\n",
    "            step_size (int): Step size for the sliding window (smaller = more samples)\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.file_paths = list(self.data_dir.glob(\"*.txt\"))\n",
    "        self.labels = labels or {}\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        # Lists to store all windows and their labels\n",
    "        self.features_list = []\n",
    "        self.labels_list = []\n",
    "        self.file_indices = []  # To keep track of which file each window came from\n",
    "        \n",
    "        # Process all files\n",
    "        print(\"Processing files and extracting windows:\")\n",
    "        for file_idx, file_path in enumerate(self.file_paths):\n",
    "            # Get category from filename\n",
    "            category = re.sub(r\"\\d+\", \"\", file_path.stem)\n",
    "            label = self.labels.get(category, -1)\n",
    "            \n",
    "            # Load and process the file\n",
    "            df = self._parse_file(file_path)\n",
    "            \n",
    "            # Create windows\n",
    "            windows_from_file = 0\n",
    "            for start_idx in range(0, len(df) - window_size + 1, step_size):\n",
    "                window = df.iloc[start_idx:start_idx + window_size]\n",
    "                \n",
    "                # Extract features from window\n",
    "                features = self._extract_features(window)\n",
    "                \n",
    "                self.features_list.append(features)\n",
    "                self.labels_list.append(label)\n",
    "                self.file_indices.append(file_idx)\n",
    "                windows_from_file += 1\n",
    "            \n",
    "            print(f\"  {file_path.name}: {windows_from_file} windows generated from {len(df)} datapoints\")\n",
    "        \n",
    "        # Convert lists to tensors for efficiency\n",
    "        self.features = torch.FloatTensor(self.features_list)\n",
    "        self.labels = torch.LongTensor(self.labels_list)\n",
    "        self.file_indices = torch.LongTensor(self.file_indices)\n",
    "        \n",
    "        # Print summary statistics\n",
    "        self._print_dataset_stats()\n",
    "        \n",
    "    def _parse_file(self, file_path: Path) -> pd.DataFrame:\n",
    "        \"\"\"Parse a single data file\"\"\"\n",
    "        df = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "        columns = [\n",
    "            'timestamp_pc', 'timestamp_micro',\n",
    "            'x', 'y', 'angle_1', 'angle_2',\n",
    "            'contact_1_left', 'contact_1_right',\n",
    "            'contact_2_left', 'contact_2_right'\n",
    "        ]\n",
    "        df = pd.DataFrame(df.values, columns=columns)\n",
    "        return df\n",
    "    \n",
    "    def _extract_features(self, window: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Extract features from a window of data\"\"\"\n",
    "        # Basic statistical features\n",
    "        features = np.array([\n",
    "            window['contact_1_left'].mean(),\n",
    "            window['contact_1_right'].mean(),\n",
    "            window['contact_2_left'].mean(),\n",
    "            window['contact_2_right'].mean(),\n",
    "            window['x'].max() - window['x'].min(),\n",
    "            window['y'].max() - window['y'].min(),\n",
    "            window['angle_1'].std(),\n",
    "            window['angle_2'].std(),\n",
    "            # Additional features for more information\n",
    "            window['contact_1_left'].std(),\n",
    "            window['contact_1_right'].std(),\n",
    "            window['contact_2_left'].std(),\n",
    "            window['contact_2_right'].std(),\n",
    "            window['angle_1'].mean(),\n",
    "            window['angle_2'].mean()\n",
    "        ])\n",
    "        return features\n",
    "    \n",
    "    def _print_dataset_stats(self):\n",
    "        \"\"\"Print statistics about the dataset\"\"\"\n",
    "        total_windows = len(self.features)\n",
    "        unique_files = len(torch.unique(self.file_indices))\n",
    "        \n",
    "        # Count samples per category\n",
    "        category_counts = {}\n",
    "        for label in self.labels_list:\n",
    "            category_name = list(CATEGORIES.keys())[list(CATEGORIES.values()).index(label)]\n",
    "            category_counts[category_name] = category_counts.get(category_name, 0) + 1\n",
    "        \n",
    "        print(\"\\nDataset Statistics:\")\n",
    "        print(f\"Total number of windows: {total_windows}\")\n",
    "        print(f\"Total number of files: {unique_files}\")\n",
    "        print(f\"Average windows per file: {total_windows / unique_files:.2f}\")\n",
    "        print(\"\\nSamples per category:\")\n",
    "        for category, count in category_counts.items():\n",
    "            print(f\"  {category}: {count} windows\")\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.features)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_by_files_robust(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the dataset by files while trying to ensure all classes are represented in each split.\n",
    "    This function handles edge cases where some classes have very few examples.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : ContactWindowDataset\n",
    "        The dataset to split\n",
    "    train_ratio : float\n",
    "        Ratio of data for training\n",
    "    val_ratio : float\n",
    "        Ratio of data for validation\n",
    "    test_ratio : float\n",
    "        Ratio of data for testing\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (train_indices, val_indices, test_indices)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Verify ratios sum to 1\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-10, \"Ratios must sum to 1\"\n",
    "    \n",
    "    # Get unique files and their labels\n",
    "    unique_file_indices = torch.unique(dataset.file_indices).numpy()\n",
    "    \n",
    "    # Create mapping from file index to most common label in that file\n",
    "    file_to_label = {}\n",
    "    for file_idx in unique_file_indices:\n",
    "        # Get all windows from this file\n",
    "        mask = dataset.file_indices == file_idx\n",
    "        window_indices = torch.where(mask)[0]\n",
    "        \n",
    "        # Get the labels for these windows\n",
    "        labels = dataset.labels[window_indices]\n",
    "        \n",
    "        # Use the most common label for this file\n",
    "        unique_labels, counts = torch.unique(labels, return_counts=True)\n",
    "        most_common_label = unique_labels[torch.argmax(counts)].item()\n",
    "        file_to_label[file_idx] = most_common_label\n",
    "    \n",
    "    # Group files by label\n",
    "    label_to_files = {}\n",
    "    for file_idx, label in file_to_label.items():\n",
    "        if label not in label_to_files:\n",
    "            label_to_files[label] = []\n",
    "        label_to_files[label].append(file_idx)\n",
    "    \n",
    "    # Print how many files per label\n",
    "    print(\"\\nFiles per label:\")\n",
    "    for label, files in label_to_files.items():\n",
    "        class_name = list(CATEGORIES.keys())[list(CATEGORIES.values()).index(label)]\n",
    "        print(f\"  {class_name}: {len(files)} files\")\n",
    "    \n",
    "    # Manual split to ensure all classes are in all splits\n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    test_files = []\n",
    "    \n",
    "    for label, files in label_to_files.items():\n",
    "        # Shuffle files for this label\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        # Calculate how many files should go to each split\n",
    "        num_files = len(files)\n",
    "        \n",
    "        if num_files >= 3:\n",
    "            # If we have enough files, use the ratios\n",
    "            num_train = max(1, int(num_files * train_ratio))\n",
    "            num_val = max(1, int(num_files * val_ratio))\n",
    "            num_test = max(1, num_files - num_train - num_val)\n",
    "            \n",
    "            # If we don't have enough files for all splits, prioritize train\n",
    "            if num_train + num_val + num_test > num_files:\n",
    "                # If we have 2 files, put one in train and one in test\n",
    "                if num_files == 2:\n",
    "                    num_train, num_val, num_test = 1, 0, 1\n",
    "                else:\n",
    "                    num_train = max(1, num_files - 2)\n",
    "                    num_val = 1\n",
    "                    num_test = 1\n",
    "            \n",
    "            # Split files\n",
    "            train_files.extend(files[:num_train])\n",
    "            val_files.extend(files[num_train:num_train+num_val])\n",
    "            test_files.extend(files[num_train+num_val:])\n",
    "        \n",
    "        elif num_files == 2:\n",
    "            # For classes with only 2 files, put one in train and one in val\n",
    "            train_files.append(files[0])\n",
    "            val_files.append(files[1])\n",
    "            # We'll handle test set separately\n",
    "        \n",
    "        elif num_files == 1:\n",
    "            # For classes with only 1 file, duplicate windows\n",
    "            # Put the file in the train set\n",
    "            train_files.append(files[0])\n",
    "            print(f\"Warning: Class {label} has only one file, putting it in train set\")\n",
    "    \n",
    "    # Now map back to window indices\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        file_idx = dataset.file_indices[idx].item()\n",
    "        if file_idx in train_files:\n",
    "            train_indices.append(idx)\n",
    "        elif file_idx in val_files:\n",
    "            val_indices.append(idx)\n",
    "        elif file_idx in test_files:\n",
    "            test_indices.append(idx)\n",
    "    \n",
    "    # Special handling for classes with only one or two files\n",
    "    # For these classes, create synthetic test examples\n",
    "    for label, files in label_to_files.items():\n",
    "        if len(files) <= 2:\n",
    "            class_indices = []\n",
    "            for idx in range(len(dataset)):\n",
    "                if dataset.labels[idx].item() == label:\n",
    "                    class_indices.append(idx)\n",
    "            \n",
    "            if len(files) == 2 and len(test_indices) == 0:\n",
    "                # If we have 2 files but none in test, move some val windows to test\n",
    "                class_val_indices = [idx for idx in class_indices if idx in val_indices]\n",
    "                if class_val_indices:\n",
    "                    # Move half of val windows to test\n",
    "                    half_point = len(class_val_indices) // 2\n",
    "                    for idx in class_val_indices[half_point:]:\n",
    "                        val_indices.remove(idx)\n",
    "                        test_indices.append(idx)\n",
    "            \n",
    "            elif len(files) == 1:\n",
    "                # If we have only 1 file, duplicate some train windows to val and test\n",
    "                class_train_indices = [idx for idx in class_indices if idx in train_indices]\n",
    "                \n",
    "                # Select random indices to duplicate (without removing from train)\n",
    "                random.shuffle(class_train_indices)\n",
    "                third_point = max(1, len(class_train_indices) // 3)\n",
    "                \n",
    "                # Add to val and test\n",
    "                val_indices.extend(class_train_indices[:third_point])\n",
    "                test_indices.extend(class_train_indices[third_point:2*third_point])\n",
    "    \n",
    "    # Print class distribution in each split\n",
    "    print(\"\\nClass distribution:\")\n",
    "    for split_name, indices in [\n",
    "        (\"Train\", train_indices), \n",
    "        (\"Validation\", val_indices), \n",
    "        (\"Test\", test_indices)\n",
    "    ]:\n",
    "        class_counts = {}\n",
    "        for idx in indices:\n",
    "            label = dataset.labels[idx].item()\n",
    "            class_name = list(CATEGORIES.keys())[list(CATEGORIES.values()).index(label)]\n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "        \n",
    "        print(f\"\\n{split_name} set:\")\n",
    "        for class_name, count in sorted(class_counts.items()):\n",
    "            print(f\"  {class_name}: {count} windows\")\n",
    "    \n",
    "    return train_indices, val_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files and extracting windows:\n",
      "  Pencilcase4.txt: 482 windows generated from 4916 datapoints\n",
      "  Pinkball3.txt: 467 windows generated from 4760 datapoints\n",
      "  Pinkball2.txt: 460 windows generated from 4695 datapoints\n",
      "  Pencilcase5.txt: 531 windows generated from 5404 datapoints\n",
      "  Pinkball1.txt: 481 windows generated from 4901 datapoints\n",
      "  Pencilcase2.txt: 615 windows generated from 6249 datapoints\n",
      "  Pinkball5.txt: 473 windows generated from 4828 datapoints\n",
      "  Pinkball4.txt: 456 windows generated from 4658 datapoints\n",
      "  Pencilcase3.txt: 602 windows generated from 6119 datapoints\n",
      "  Pencilcase1.txt: 504 windows generated from 5135 datapoints\n",
      "  Pinkball6.txt: 458 windows generated from 4679 datapoints\n",
      "  Box4.txt: 483 windows generated from 4926 datapoints\n",
      "  Box5.txt: 530 windows generated from 5399 datapoints\n",
      "  Box1.txt: 509 windows generated from 5187 datapoints\n",
      "  Box2.txt: 467 windows generated from 4766 datapoints\n",
      "  Box3.txt: 484 windows generated from 4939 datapoints\n",
      "  Blueball6.txt: 470 windows generated from 4792 datapoints\n",
      "  Waterbottle4.txt: 538 windows generated from 5471 datapoints\n",
      "  Blueball5.txt: 470 windows generated from 4790 datapoints\n",
      "  Blueball4.txt: 471 windows generated from 4802 datapoints\n",
      "  Waterbottle5.txt: 485 windows generated from 4948 datapoints\n",
      "  Waterbottle1.txt: 488 windows generated from 4971 datapoints\n",
      "  Blueball1.txt: 449 windows generated from 4581 datapoints\n",
      "  Waterbottle2.txt: 466 windows generated from 4750 datapoints\n",
      "  Blueball3.txt: 456 windows generated from 4656 datapoints\n",
      "  Blueball2.txt: 469 windows generated from 4781 datapoints\n",
      "  Waterbottle3.txt: 467 windows generated from 4768 datapoints\n",
      "  StuffedAnimal1.txt: 464 windows generated from 4732 datapoints\n",
      "  Tennis1.txt: 500 windows generated from 5093 datapoints\n",
      "  Tennis3.txt: 493 windows generated from 5025 datapoints\n",
      "  StuffedAnimal2.txt: 507 windows generated from 5169 datapoints\n",
      "  StuffedAnimal3.txt: 510 windows generated from 5192 datapoints\n",
      "  Tennis2.txt: 631 windows generated from 6405 datapoints\n",
      "  Tennis5.txt: 466 windows generated from 4756 datapoints\n",
      "  StuffedAnimal4.txt: 491 windows generated from 5008 datapoints\n",
      "  StuffedAnimal5.txt: 352 windows generated from 3615 datapoints\n",
      "  Tennis4.txt: 524 windows generated from 5330 datapoints\n",
      "\n",
      "Dataset Statistics:\n",
      "Total number of windows: 18169\n",
      "Total number of files: 37\n",
      "Average windows per file: 491.05\n",
      "\n",
      "Samples per category:\n",
      "  Pencilcase: 2734 windows\n",
      "  Pinkball: 2795 windows\n",
      "  Box: 2473 windows\n",
      "  Blueball: 2785 windows\n",
      "  Waterbottle: 2444 windows\n",
      "  StuffedAnimal: 2324 windows\n",
      "  Tennis: 2614 windows\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset with smaller window and step size to maximize samples\n",
    "window_size = 100   # Smaller window size generates more samples\n",
    "step_size = 10     # Smaller step size creates more overlapping windows\n",
    "dataset = ContactWindowDataset(\n",
    "    data_dir=config[\"data_dir\"], \n",
    "    labels=CATEGORIES, \n",
    "    window_size=window_size, \n",
    "    step_size=step_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files per label:\n",
      "  Pencilcase: 5 files\n",
      "  Pinkball: 6 files\n",
      "  Box: 5 files\n",
      "  Blueball: 6 files\n",
      "  Waterbottle: 5 files\n",
      "  StuffedAnimal: 5 files\n",
      "  Tennis: 5 files\n",
      "\n",
      "Class distribution:\n",
      "\n",
      "Train set:\n",
      "  Blueball: 1846 windows\n",
      "  Box: 1506 windows\n",
      "  Pencilcase: 1748 windows\n",
      "  Pinkball: 1877 windows\n",
      "  StuffedAnimal: 1481 windows\n",
      "  Tennis: 1459 windows\n",
      "  Waterbottle: 1439 windows\n",
      "\n",
      "Validation set:\n",
      "  Blueball: 469 windows\n",
      "  Box: 483 windows\n",
      "  Pencilcase: 504 windows\n",
      "  Pinkball: 458 windows\n",
      "  StuffedAnimal: 491 windows\n",
      "  Tennis: 631 windows\n",
      "  Waterbottle: 538 windows\n",
      "\n",
      "Test set:\n",
      "  Blueball: 470 windows\n",
      "  Box: 484 windows\n",
      "  Pencilcase: 482 windows\n",
      "  Pinkball: 460 windows\n",
      "  StuffedAnimal: 352 windows\n",
      "  Tennis: 524 windows\n",
      "  Waterbottle: 467 windows\n",
      "\n",
      "Dataset Splits:\n",
      "Training set size: 11356 windows\n",
      "Validation set size: 3574 windows\n",
      "Test set size: 3239 windows\n",
      "\n",
      "Sample batch:\n",
      "Batch features shape: torch.Size([32, 14])\n",
      "Batch labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset by files to prevent data leakage\n",
    "train_indices, val_indices, test_indices = split_dataset_by_files_robust(dataset)  # Use _robust instead of _stratified\n",
    "\n",
    "# Create subset datasets\n",
    "from torch.utils.data import Subset\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'])\n",
    "\n",
    "# Print split information\n",
    "print(\"\\nDataset Splits:\")\n",
    "print(f\"Training set size: {len(train_dataset)} windows\")\n",
    "print(f\"Validation set size: {len(val_dataset)} windows\")\n",
    "print(f\"Test set size: {len(test_dataset)} windows\")\n",
    "\n",
    "# Example of accessing a batch\n",
    "for features, labels in train_loader:\n",
    "    print(f\"\\nSample batch:\")\n",
    "    print(f\"Batch features shape: {features.shape}\")\n",
    "    print(f\"Batch labels shape: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 64]             960\n",
      "       BatchNorm1d-2                   [-1, 64]             128\n",
      "              ReLU-3                   [-1, 64]               0\n",
      "            Conv1d-4              [-1, 128, 50]          57,472\n",
      "       BatchNorm1d-5              [-1, 128, 50]             256\n",
      "              ReLU-6              [-1, 128, 50]               0\n",
      "         MaxPool1d-7              [-1, 128, 25]               0\n",
      "            Conv1d-8              [-1, 256, 25]          33,024\n",
      "       BatchNorm1d-9              [-1, 256, 25]             512\n",
      "           Conv1d-10              [-1, 256, 25]          98,560\n",
      "      BatchNorm1d-11              [-1, 256, 25]             512\n",
      "             ReLU-12              [-1, 256, 25]               0\n",
      "           Conv1d-13              [-1, 256, 25]         196,864\n",
      "      BatchNorm1d-14              [-1, 256, 25]             512\n",
      "             ReLU-15              [-1, 256, 25]               0\n",
      "  Temporal1DBlock-16              [-1, 256, 25]               0\n",
      "           Conv1d-17              [-1, 512, 25]         131,584\n",
      "      BatchNorm1d-18              [-1, 512, 25]           1,024\n",
      "           Conv1d-19              [-1, 512, 25]         393,728\n",
      "      BatchNorm1d-20              [-1, 512, 25]           1,024\n",
      "             ReLU-21              [-1, 512, 25]               0\n",
      "           Conv1d-22              [-1, 512, 25]         786,944\n",
      "      BatchNorm1d-23              [-1, 512, 25]           1,024\n",
      "             ReLU-24              [-1, 512, 25]               0\n",
      "  Temporal1DBlock-25              [-1, 512, 25]               0\n",
      "           Conv1d-26             [-1, 1024, 25]         525,312\n",
      "      BatchNorm1d-27             [-1, 1024, 25]           2,048\n",
      "           Conv1d-28             [-1, 1024, 25]       1,573,888\n",
      "      BatchNorm1d-29             [-1, 1024, 25]           2,048\n",
      "             ReLU-30             [-1, 1024, 25]               0\n",
      "           Conv1d-31             [-1, 1024, 25]       3,146,752\n",
      "      BatchNorm1d-32             [-1, 1024, 25]           2,048\n",
      "             ReLU-33             [-1, 1024, 25]               0\n",
      "  Temporal1DBlock-34             [-1, 1024, 25]               0\n",
      "AdaptiveAvgPool1d-35              [-1, 1024, 1]               0\n",
      "          Dropout-36                 [-1, 1024]               0\n",
      "           Linear-37                 [-1, 1024]       1,049,600\n",
      "      BatchNorm1d-38                 [-1, 1024]           2,048\n",
      "           Linear-39                    [-1, 7]           7,175\n",
      "================================================================\n",
      "Total params: 8,015,047\n",
      "Trainable params: 8,015,047\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.28\n",
      "Params size (MB): 30.57\n",
      "Estimated Total Size (MB): 33.85\n",
      "----------------------------------------------------------------\n",
      "Model moved to MPS device\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "class Temporal1DBlock(nn.Module):\n",
    "    \"\"\"Residual block for 1D time series data\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1):\n",
    "        super(Temporal1DBlock, self).__init__()\n",
    "        # Calculate padding to maintain temporal dimension\n",
    "        padding = dilation * (kernel_size - 1) // 2\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding=padding,\n",
    "                              dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              padding=padding,\n",
    "                              dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        self.shortcut_bn = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        identity = self.shortcut_bn(identity)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class TimeSeriesClassifier(nn.Module):\n",
    "    def __init__(self, input_features, num_classes, window_size=50):\n",
    "        \"\"\"\n",
    "        Time Series Classifier using ResNet architecture\n",
    "        \n",
    "        Args:\n",
    "            input_features: Number of features in each time step\n",
    "            num_classes: Number of output classes\n",
    "            window_size: Size of the time window\n",
    "        \"\"\"\n",
    "        super(TimeSeriesClassifier, self).__init__()\n",
    "        \n",
    "        self.input_features = input_features\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Feature enrichment module - expand features\n",
    "        self.feature_embedding = nn.Sequential(\n",
    "            nn.Linear(input_features, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Initial convolution layer\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks with increasing dilation for larger receptive field\n",
    "        self.res1 = Temporal1DBlock(128, 256, dilation=1)\n",
    "        self.res2 = Temporal1DBlock(256, 512, dilation=2)  # Increased dilation\n",
    "        self.res3 = Temporal1DBlock(512, 1024, dilation=4)  # Further increased dilation\n",
    "        \n",
    "        # Global pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Fully connected classifier\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc1 = nn.Linear(1024, 1024)\n",
    "        self.bn = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input handling: [batch_size, features, time_steps] or [batch_size, features]\n",
    "        if len(x.shape) == 2:\n",
    "            # If input is [batch_size, features], reshape to [batch_size, features, 1]\n",
    "            x = x.unsqueeze(-1)\n",
    "            \n",
    "            # For contact data, we assume features are measurements at a point in time\n",
    "            # Here we need to enrich the feature representation\n",
    "            batch_size = x.shape[0]\n",
    "            x = x.transpose(1, 2)  # [batch_size, 1, features]\n",
    "            x = x.view(batch_size, -1)  # [batch_size, features]\n",
    "            \n",
    "            # Apply feature embedding\n",
    "            x = self.feature_embedding(x)  # [batch_size, 64]\n",
    "            x = x.unsqueeze(-1)  # [batch_size, 64, 1]\n",
    "            \n",
    "            # Repeat the features across the window to simulate a time series\n",
    "            x = x.repeat(1, 1, self.window_size)  # [batch_size, 64, window_size]\n",
    "        \n",
    "        # Normal case when x is already [batch_size, features, time_steps]\n",
    "        elif len(x.shape) == 3:\n",
    "            # Apply feature embedding to each time step\n",
    "            batch_size, features, time_steps = x.shape\n",
    "            x = x.transpose(1, 2)  # [batch_size, time_steps, features]\n",
    "            x = x.reshape(-1, features)  # [batch_size*time_steps, features]\n",
    "            x = self.feature_embedding(x)  # [batch_size*time_steps, 64]\n",
    "            x = x.view(batch_size, time_steps, 64)  # [batch_size, time_steps, 64]\n",
    "            x = x.transpose(1, 2)  # [batch_size, 64, time_steps]\n",
    "        \n",
    "        # Convolutional feature extraction\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Residual blocks\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = self.global_pool(x).squeeze(-1)  # [batch_size, 1024]\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn(x)\n",
    "        feats = x  # Store features\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        # Return both features and output\n",
    "        return {\"feats\": feats, \"out\": out}\n",
    "\n",
    "# Initialize the model (usage example)\n",
    "input_features = 14  # Number of features in your dataset\n",
    "window_size = 50  # Size of time window\n",
    "num_classes = len(CATEGORIES)\n",
    "model = TimeSeriesClassifier(input_features, num_classes, window_size)\n",
    "\n",
    "# Try CPU first for compatibility with BatchNorm1d \n",
    "device = torch.device('cpu')  # Change to 'mps' after checking summary\n",
    "model.to(device)\n",
    "summary(model, (input_features,))\n",
    "\n",
    "# After checking summary, move to MPS if available\n",
    "try:\n",
    "    if torch.backends.mps.is_available():\n",
    "        model = model.to('mps')\n",
    "        device = torch.device('mps')\n",
    "        print(\"Model moved to MPS device\")\n",
    "    print(f\"Using device: {device}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error moving to MPS: {e}\")\n",
    "    print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    maxk = min(max(topk), output.size()[1])\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "    return [correct[:min(k, maxk)].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    # Metric meters\n",
    "    loss_m = AverageMeter()\n",
    "    acc_m = AverageMeter()\n",
    "    \n",
    "    # Progress Bar\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        \n",
    "        # Get the data\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs['out'], y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = accuracy(outputs['out'], y)[0].item()\n",
    "        \n",
    "        # Update meters\n",
    "        loss_m.update(loss.item())\n",
    "        acc_m.update(acc)\n",
    "        \n",
    "        # Update progress bar\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(float(loss_m.avg)),\n",
    "            acc=\"{:.04f}%\".format(float(acc_m.avg)),\n",
    "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr']))\n",
    "        )\n",
    "        batch_bar.update()\n",
    "        \n",
    "        # Memory management\n",
    "        del x, y, outputs, loss\n",
    "        if hasattr(torch.mps, 'empty_cache'):\n",
    "            torch.mps.empty_cache()\n",
    "    \n",
    "    batch_bar.close()\n",
    "    return acc_m.avg, loss_m.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_model(model, val_loader, criterion, class_names, device):\n",
    "    model.eval()\n",
    "    # Metric meters\n",
    "    loss_m = AverageMeter()\n",
    "    acc_m = AverageMeter()\n",
    "    \n",
    "    # Progress Bar\n",
    "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for i, data in enumerate(val_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs['out'], y)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = accuracy(outputs['out'], y)[0].item()\n",
    "        \n",
    "        # Store predictions and targets for confusion matrix\n",
    "        _, predicted = torch.max(outputs['out'], 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(y.cpu().numpy())\n",
    "        \n",
    "        # Update meters\n",
    "        loss_m.update(loss.item())\n",
    "        acc_m.update(acc)\n",
    "        \n",
    "        # Update progress bar\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(float(loss_m.avg)),\n",
    "            acc=\"{:.04f}%\".format(float(acc_m.avg))\n",
    "        )\n",
    "        batch_bar.update()\n",
    "        \n",
    "        # Memory management\n",
    "        del x, y, outputs, loss\n",
    "        if hasattr(torch.mps, 'empty_cache'):\n",
    "            torch.mps.empty_cache()\n",
    "    \n",
    "    batch_bar.close()\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    if class_names:\n",
    "        print(\"\\nPer-class Validation Accuracy:\")\n",
    "        per_class_acc = {}\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            class_mask = (np.array(all_targets) == i)\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_correct = np.sum((np.array(all_preds)[class_mask] == i))\n",
    "                class_total = np.sum(class_mask)\n",
    "                accuracy = 100 * class_correct / class_total\n",
    "                print(f\"  {class_name}: {accuracy:.4f}% ({class_correct}/{class_total})\")\n",
    "                per_class_acc[f\"val_acc_{class_name}\"] = accuracy\n",
    "    \n",
    "    return acc_m.avg, loss_m.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        \n",
    "        # Handle dictionary output format\n",
    "        if isinstance(outputs, dict) and 'out' in outputs:\n",
    "            logits = outputs['out']  # Extract the classification logits\n",
    "        else:\n",
    "            logits = outputs\n",
    "            \n",
    "        # Calculate loss with the extracted logits\n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(logits, 1)  # Use the extracted logits\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        \n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            acc=\"{:.04f}\".format(float(correct / total)),\n",
    "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr']))\n",
    "        )\n",
    "        batch_bar.update()\n",
    "        \n",
    "        # Memory management\n",
    "        del x, y, outputs, loss\n",
    "        if hasattr(torch.mps, 'empty_cache'):\n",
    "            torch.mps.empty_cache()\n",
    "    \n",
    "    batch_bar.close()\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_acc = correct / total * 100\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, criterion, class_names, device):\n",
    "    model.eval()\n",
    "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for i, data in enumerate(val_loader):\n",
    "        x, y = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(x)\n",
    "            \n",
    "            # Handle dictionary output format\n",
    "            if isinstance(outputs, dict) and 'out' in outputs:\n",
    "                logits = outputs['out']  # Extract the classification logits\n",
    "            else:\n",
    "                logits = outputs\n",
    "                \n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(logits, 1)  # Use the extracted logits\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "            # Store predictions and targets for confusion matrix\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            batch_bar.set_postfix(\n",
    "                loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "                acc=\"{:.04f}\".format(float(correct / total))\n",
    "            )\n",
    "            batch_bar.update()\n",
    "            \n",
    "            # Memory management\n",
    "            del x, y, outputs, loss\n",
    "            if hasattr(torch.mps, 'empty_cache'):\n",
    "                torch.mps.empty_cache()\n",
    "    \n",
    "    batch_bar.close()\n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    val_acc = correct / total * 100\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, metrics, epoch, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'metrics': metrics\n",
    "    }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define CrossEntropyLoss as the criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize optimizer with AdamW\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"78d5988d9f05a421bc74d044c3cd9afc3b918020\") # API Key is in your wandb account, under settings (wandb.ai/settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb\n",
    "run = wandb.init(\n",
    "    name = \"06run\", ## Wandb creates random run names if you skip this field\n",
    "    reinit = False, ### Allows reinitalizing runs when you re-run this cell\n",
    "    #id = \"\", ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"object_classification\", ### Project should be created in your wandb account\n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0493, Train Accuracy: 20.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4744, Validation Accuracy: 11.89%\n",
      "Saved best model with validation loss: 2.4744 and accuracy: 11.89%\n",
      "Saved model for epoch 1\n",
      "End of Epoch 1/20\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9608, Train Accuracy: 20.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5482, Validation Accuracy: 13.54%\n",
      "Saved model for epoch 2\n",
      "End of Epoch 2/20\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9379, Train Accuracy: 23.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.0957, Validation Accuracy: 15.70%\n",
      "Saved best model with validation loss: 2.0957 and accuracy: 15.70%\n",
      "Saved model for epoch 3\n",
      "End of Epoch 3/20\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8857, Train Accuracy: 25.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.1225, Validation Accuracy: 19.70%\n",
      "Saved model for epoch 4\n",
      "End of Epoch 4/20\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8327, Train Accuracy: 26.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5162, Validation Accuracy: 18.49%\n",
      "Saved model for epoch 5\n",
      "End of Epoch 5/20\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7841, Train Accuracy: 27.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2188, Validation Accuracy: 20.03%\n",
      "Saved model for epoch 6\n",
      "End of Epoch 6/20\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7663, Train Accuracy: 29.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.8273, Validation Accuracy: 21.77%\n",
      "Saved model for epoch 7\n",
      "End of Epoch 7/20\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7370, Train Accuracy: 30.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.8580, Validation Accuracy: 24.29%\n",
      "Saved model for epoch 8\n",
      "End of Epoch 8/20\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7109, Train Accuracy: 31.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2679, Validation Accuracy: 21.77%\n",
      "Saved model for epoch 9\n",
      "End of Epoch 9/20\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6022, Train Accuracy: 35.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2971, Validation Accuracy: 19.73%\n",
      "Saved model for epoch 10\n",
      "End of Epoch 10/20\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5815, Train Accuracy: 35.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2729, Validation Accuracy: 20.15%\n",
      "Saved model for epoch 11\n",
      "End of Epoch 11/20\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5595, Train Accuracy: 36.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3722, Validation Accuracy: 20.03%\n",
      "Saved model for epoch 12\n",
      "End of Epoch 12/20\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5504, Train Accuracy: 36.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6182, Validation Accuracy: 19.39%\n",
      "Saved model for epoch 13\n",
      "End of Epoch 13/20\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5322, Train Accuracy: 36.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3061, Validation Accuracy: 22.16%\n",
      "Saved model for epoch 14\n",
      "End of Epoch 14/20\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5440, Train Accuracy: 36.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4020, Validation Accuracy: 17.60%\n",
      "Saved model for epoch 15\n",
      "End of Epoch 15/20\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4812, Train Accuracy: 38.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3702, Validation Accuracy: 21.04%\n",
      "Saved model for epoch 16\n",
      "End of Epoch 16/20\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4518, Train Accuracy: 39.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4648, Validation Accuracy: 21.15%\n",
      "Saved model for epoch 17\n",
      "End of Epoch 17/20\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4504, Train Accuracy: 39.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4121, Validation Accuracy: 20.51%\n",
      "Saved model for epoch 18\n",
      "End of Epoch 18/20\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4291, Train Accuracy: 40.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4300, Validation Accuracy: 20.57%\n",
      "Saved model for epoch 19\n",
      "End of Epoch 19/20\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4332, Train Accuracy: 40.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5615, Validation Accuracy: 19.75%\n",
      "Saved model for epoch 20\n",
      "End of Epoch 20/20\n",
      "\n",
      "Training complete! Best validation accuracy: 15.70%\n"
     ]
    }
   ],
   "source": [
    "# Create checkpoint directory if it doesn't exist\n",
    "os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
    "\n",
    "# Initialize best metrics tracking\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0\n",
    "class_names = list(CATEGORIES.keys())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{config['epochs']}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_acc = validate_model(model, val_loader, criterion, class_names, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save best model based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        \n",
    "        # Save best model\n",
    "        best_model_path = os.path.join(config['checkpoint_dir'], 'best_model.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "        }, best_model_path)\n",
    "        wandb.save(best_model_path)  # Save the model to WandB\n",
    "        print(f\"Saved best model with validation loss: {best_val_loss:.4f} and accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # Save the model for every epoch\n",
    "    last_model_path = os.path.join(config['checkpoint_dir'], f'model_epoch_{epoch+1}.pth')\n",
    "    torch.save(model.state_dict(), last_model_path)\n",
    "    wandb.save(last_model_path)  # Save the model to WandB\n",
    "    print(f\"Saved model for epoch {epoch+1}\")\n",
    "    \n",
    "    # Logging metrics to WandB\n",
    "    wandb.log({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'learning_rate': curr_lr\n",
    "    }, step=epoch)\n",
    "    \n",
    "    print(f\"End of Epoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "# Final message\n",
    "print(f\"\\nTraining complete! Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, class_names, device, checkpoint_dir=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset and generate detailed performance metrics\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Initialize metrics\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Store all predictions and ground truth for analysis\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = [] # Store probabilities for confidence analysis\n",
    "    # Per-class statistics\n",
    "    class_correct = {class_name: 0 for class_name in class_names}\n",
    "    class_total = {class_name: 0 for class_name in class_names}\n",
    "    # Create progress bar\n",
    "    test_bar = tqdm(test_loader, desc=\"Testing\", unit=\"batch\", ncols=100)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_bar:\n",
    "            # Get inputs and labels\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Handle different output formats (dictionary vs. tensor)\n",
    "            if isinstance(outputs, dict) and 'out' in outputs:\n",
    "                outputs_for_loss = outputs['out']\n",
    "            else:\n",
    "                outputs_for_loss = outputs\n",
    "                \n",
    "            loss = criterion(outputs_for_loss, targets)\n",
    "            \n",
    "            # Calculate loss and accuracy\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            if isinstance(outputs, dict) and 'out' in outputs:\n",
    "                probs = torch.nn.functional.softmax(outputs['out'], dim=1)\n",
    "                _, predicted = torch.max(outputs['out'], 1)\n",
    "            else:\n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Update total counts\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            # Update per-class counts\n",
    "            for i in range(targets.size(0)):\n",
    "                label = targets[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_name = class_names[label]\n",
    "                class_total[class_name] += 1\n",
    "                if pred == label:\n",
    "                    class_correct[class_name] += 1\n",
    "            \n",
    "            # Store predictions and targets for later analysis\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            test_bar.set_postfix({\n",
    "                'loss': f\"{test_loss/total:.4f}\",\n",
    "                'acc': f\"{100.0*correct/total:.2f}%\"\n",
    "            })\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct / total\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracy = {name: class_correct[name]/class_total[name] if class_total[name] > 0 else 0\n",
    "                    for name in class_names}\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TEST RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f} ({correct}/{total})\")\n",
    "    print(\"\\nPer-Class Accuracy:\")\n",
    "    for class_name in class_names:\n",
    "        print(f\" {class_name}: {class_accuracy[class_name]:.4f} ({class_correct[class_name]}/{class_total[class_name]})\")\n",
    "\n",
    "    # Return comprehensive metrics dictionary\n",
    "    return {\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_acc,\n",
    "        'class_accuracy': class_accuracy,\n",
    "        'predictions': all_preds,\n",
    "        'targets': all_targets,\n",
    "        'probabilities': all_probs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████| 102/102 [00:01<00:00, 55.47batch/s, loss=2.4158, acc=23.16%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEST RESULTS\n",
      "==================================================\n",
      "Test Loss: 2.4158\n",
      "Test Accuracy: 0.2316 (750/3239)\n",
      "\n",
      "Per-Class Accuracy:\n",
      " Blueball: 0.1745 (82/470)\n",
      " Box: 0.2521 (122/484)\n",
      " Pencilcase: 0.2427 (117/482)\n",
      " Pinkball: 0.3478 (160/460)\n",
      " StuffedAnimal: 0.0170 (6/352)\n",
      " Tennis: 0.3588 (188/524)\n",
      " Waterbottle: 0.1606 (75/467)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Load the best model (optional - if you saved a checkpoint)\n",
    "# best_model_path = f\"{config['checkpoint_dir']}/best_model.pth\"\n",
    "# if os.path.exists(best_model_path):\n",
    "#     checkpoint = torch.load(best_model_path)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     print(f\"Loaded best model from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = test_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    class_names=class_names,\n",
    "    device=device,\n",
    "    checkpoint_dir=config['checkpoint_dir']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>██████▄▄▄▄▄▄▂▂▂▂▂▂▁▂</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▄▅▅▆▆▆▆▇▇█████▇</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▃▁▃▃▄▇▆▃▅▆▅▆▇▆▅█▇█▇▅</td></tr><tr><td>val_loss</td><td>▁▃▂▂▄▃▄▅▃▄▄▃▄▅▅█▆▆▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>learning_rate</td><td>0.00025</td></tr><tr><td>train_acc</td><td>40.65692</td></tr><tr><td>train_loss</td><td>1.43315</td></tr><tr><td>val_acc</td><td>19.75378</td></tr><tr><td>val_loss</td><td>2.56151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">06run</strong> at: <a href='https://wandb.ai/donggul-carnegie-mellon-university/object_classification/runs/32c7zslb' target=\"_blank\">https://wandb.ai/donggul-carnegie-mellon-university/object_classification/runs/32c7zslb</a><br> View project at: <a href='https://wandb.ai/donggul-carnegie-mellon-university/object_classification' target=\"_blank\">https://wandb.ai/donggul-carnegie-mellon-university/object_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 21 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250315_134407-32c7zslb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
